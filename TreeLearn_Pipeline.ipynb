{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ecker-lab/TreeLearn/blob/main/TreeLearn_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ0XVazsDLEM"
      },
      "source": [
        "## Example Notebook for TreeLearn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTNLHg1A4hTJ"
      },
      "source": [
        "Thank you for your interest in our TreeLearn method! With this notebook and google colab, you can try out the pipeline for segmenting a forest point cloud without installing anything on your own computer!\n",
        "\n",
        "You need to be signed in with your google account. Please also make sure that you are connected to a gpu runtime by by selecting 'runtime' change runtime to e.g. T4 GPU. The following code snippet will show a table with gpu information if you are connnected to a gpu runtime. To run the code snippet, simply click on the left edge. or press (Ctrl + enter) after selecting it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI42xeR55Qsl"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following two code snippets are necessary to set up the environment and download the model weights. Simply run them before continuing. It takes 2 to 3 minutes."
      ],
      "metadata": {
        "id": "fCl6z0uNseOV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SYchH0wLXqx"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# install environment\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
        "!pip install timm==0.6.12\n",
        "!pip install tensorboard\n",
        "!pip install tensorboardX\n",
        "!pip install laspy[lazrs]==2.5.1\n",
        "!pip install munch==2.5.0\n",
        "!pip install pandas==2.0.0\n",
        "!pip install plyfile==0.9\n",
        "!pip install pyyaml==6.0\n",
        "!pip install scikit-learn==1.2.2\n",
        "!pip install six==1.16.0\n",
        "!pip install tqdm==4.65.0\n",
        "!pip install open3d-cpu==0.17.0 --default-timeout=100\n",
        "!pip install jakteristics==0.5.1\n",
        "!pip install shapely==2.0.1\n",
        "!pip install geopandas==0.12.2\n",
        "!pip install alphashape==1.3.1\n",
        "!pip install plotly-express==0.4.1 --default-timeout=100\n",
        "!pip install spconv-cu114 --default-timeout=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qxJEvNu9kGm"
      },
      "outputs": [],
      "source": [
        "#%%capture\n",
        "!git clone https://github.com/ecker-lab/TreeLearn.git\n",
        "%cd TreeLearn\n",
        "!pip install -e .\n",
        "%cd ..\n",
        "!mkdir data\n",
        "!mkdir checkpoints\n",
        "!mkdir pipeline\n",
        "!mkdir pipeline/forests\n",
        "path = \"/content/checkpoints/model_weights.pth\"\n",
        "!wget https://data.goettingen-research-online.de/api/access/datafile/:persistentId?persistentId=doi:10.25625/VPMPID/1JMEQV -O $path\n",
        "\n",
        "%cd TreeLearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra8mJVagRvlI"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first need to decide which point cloud we want to segment. The following code snippet downloads an example point cloud segment that we did not train on.\n",
        "If you want to try out another forest point cloud, replace the download with your own. Make sure that the file is in the .npy, .npz, .las, .laz or .txt file format and the total size of the forest plot should be around 1600 m^2 at maximum. Please note that with a forest point cloud of this size the segmentation took in our runs around 15 minutes in google colab due to limited computation resources."
      ],
      "metadata": {
        "id": "INqgac0r0KQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forest_name = \"plot_7_cut.laz\"\n",
        "path = \"/content/pipeline/forests/\" + forest_name\n",
        "!wget https://data.goettingen-research-online.de/api/access/datafile/:persistentId?persistentId=doi:10.25625/VPMPID/0WDXL6 -O $path"
      ],
      "metadata": {
        "id": "25148d-10JxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To run the TreeLearn pipeline interactively in google colab, we import the function run_treelearn_pipeline. This function takes as argument the config dict. We import the pipeline.yaml as the config dict and print it.\n",
        "\n",
        "We adjust some entries in the config dict to fit to the setting in google colab and speed up the pipeline. We also initialize the logger so that the progress in the pipeline is printed.\n"
      ],
      "metadata": {
        "id": "tZREpAa-s0Fp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPbQGPxNdwzL"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/TreeLearn/tools/pipeline\")\n",
        "from pipeline import run_treelearn_pipeline\n",
        "import argparse, pprint\n",
        "from tree_learn.util import get_config\n",
        "\n",
        "config_path = \"/content/TreeLearn/configs/pipeline/pipeline.yaml\"\n",
        "config = get_config(config_path)\n",
        "\n",
        "# adjust config\n",
        "config.forest_path = \"/content/pipeline/forests/\" + forest_name\n",
        "config.dataset_test.data_root = \"/content/pipeline/tiles\"\n",
        "config.tile_generation = True\n",
        "config.pretrain = \"/content/checkpoints/model_weights.pth\"\n",
        "config.sample_generation.stride = 0.9 # small overlap\n",
        "config.shape_cfg.outer_remove = False # default value = 11\n",
        "config.save_cfg.save_treewise = False\n",
        "config.save_cfg.return_type = \"voxelized_and_filtered\"\n",
        "print(pprint.pformat(config.toDict(), indent=2))\n",
        "\n",
        "import logging\n",
        "logger = logging.getLogger(\"softgroup\")\n",
        "for handler in logger.handlers[:]:\n",
        "    logger.removeHandler(handler)\n",
        "logging.basicConfig()\n",
        "ch = logging.StreamHandler(sys.stdout)\n",
        "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "ch.setFormatter(formatter)\n",
        "logger.addHandler(ch)\n",
        "logger.setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After having set all the correct settings in the config file, it remains to run the pipeline. Please keep in mind that fully running it for the example point cloud takes around 15 minutes.\n",
        "\n"
      ],
      "metadata": {
        "id": "6neoLf6l2zcF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKh7yZ3ld1o3"
      },
      "outputs": [],
      "source": [
        "# run pipeline\n",
        "run_treelearn_pipeline(config)\n",
        "# runtime ~ 10 min"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If everything has run as expected, the segmented point cloud is now saved in the .laz format with labels in the directory /content/pipeline/results. It is also saved in the .npz format. You can easily download it by right-clicking and selecting download. Please note, that the border of the point cloud is not removed in this notebook. Trees that are only partially within the scan area will not be properly segmented since the network is trained to project the points towards the trunk."
      ],
      "metadata": {
        "id": "zroEoOMU5DOO"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}