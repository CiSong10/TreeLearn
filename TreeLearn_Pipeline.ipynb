{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ecker-lab/TreeLearn/blob/main/TreeLearn_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ0XVazsDLEM"
      },
      "source": [
        "## Example Notebook for TreeLearn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTNLHg1A4hTJ"
      },
      "source": [
        "Thank you for your interest in our TreeLearn method! With this notebook and google colab, you can try out the pipeline for segmenting a forest point cloud without installing anything on your own computer!\n",
        "\n",
        "You need to be signed in with your google account. Please also make sure that you are connected to a gpu runtime by by selecting 'runtime' change runtime to e.g. T4 GPU. The following code snippet will show a table with gpu information if you are connnected to a gpu runtime. To run the code snippet, simply click on the left edge. or press (Ctrl + enter) after selecting it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI42xeR55Qsl",
        "outputId": "cdc48ab8-9282-4453-fa82-d7661996327b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov  7 12:25:10 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following two code snippets are necessary to set up the environment and download the model checkpoints. Simply run them before continuing. It takes 2 to 3 minutes."
      ],
      "metadata": {
        "id": "fCl6z0uNseOV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SYchH0wLXqx"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# install environment\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
        "!pip install timm==0.6.12\n",
        "!pip install tensorboard\n",
        "!pip install gdown\n",
        "!pip install tensorboardX\n",
        "\n",
        "!pip install munch==2.5.0\n",
        "!pip install pandas==2.0.0\n",
        "!pip install plyfile==0.9\n",
        "!pip install pyyaml==6.0\n",
        "!pip install scikit-learn==1.2.2\n",
        "!pip install six==1.16.0\n",
        "!pip install tqdm==4.65.0\n",
        "!pip install open3d-cpu==0.17.0 --default-timeout=100\n",
        "!pip install jakteristics==0.5.1\n",
        "!pip install shapely==2.0.1\n",
        "!pip install geopandas==0.12.2\n",
        "!pip install alphashape==1.3.1\n",
        "!pip install plotly-express==0.4.1 --default-timeout=100\n",
        "!pip install spconv-cu114 --default-timeout=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0qxJEvNu9kGm"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/ecker-lab/TreeLearn.git\n",
        "%cd TreeLearn\n",
        "!pip install -e .\n",
        "%cd ..\n",
        "!mkdir data\n",
        "!mkdir checkpoints\n",
        "!mkdir pipeline\n",
        "!mkdir pipeline/forests\n",
        "#!python TreeLearn/tree_learn/util/download.py --dataset_name checkpoints --root_folder /content/checkpoints\n",
        "\n",
        "import gdown\n",
        "link = \"https://drive.google.com/uc?id=1GrJ-kq-9_bxiFG_E8wPR0J8JMmlY5D4-\"\n",
        "folder = \"/content/checkpoints/finetuned_checkpoint_classifier.pth\"\n",
        "gdown.download(link, folder)\n",
        "link = \"https://drive.google.com/uc?id=1--n-qwcjLtT_g8JjjZShj9QwAnxQFsK-\"\n",
        "folder = \"/content/checkpoints/finetuned_checkpoint_pointwise_prediction.pth\"\n",
        "gdown.download(link, folder)\n",
        "\n",
        "%cd TreeLearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra8mJVagRvlI"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first need to decide which point cloud we want to segment. The following code snippet downloads an example point cloud segment that we did not train on. The size is 40 x 40 meters.\n",
        "\n",
        "If you want to try out another forest point cloud, replace the download with your own. Make sure that the file is in the .npy or the .txt file format and the total size of the forest stretch should be around 1600 m^2 at maximum. The point cloud should only contain the three columns with x, y and z values and no labels. Please note that with a forest point cloud of this size the segmentation took in our runs around 15 minutes in google colab due to limited computation resources.\n",
        "\n",
        "Please note that our models have been trained on tls/mls data of forests dominated by beech. **We expect that for a good performance on e.g. uav data and other forest types, finetuning the models is necessary.**"
      ],
      "metadata": {
        "id": "INqgac0r0KQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "forest_name = \"plot_7_cut.npy\"\n",
        "link = \"https://drive.google.com/uc?id=1V6-JvDnQn1_koAdbcquSgP9B81xWrNWs\"\n",
        "folder = \"/content/pipeline/forests/\" + forest_name\n",
        "gdown.download(link, folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "25148d-10JxJ",
        "outputId": "0f9c9b66-f7d2-484d-e426-2b4374d96fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1V6-JvDnQn1_koAdbcquSgP9B81xWrNWs\n",
            "To: /content/pipeline/forests/plot_7_cut.npy\n",
            "100%|██████████| 92.3M/92.3M [00:00<00:00, 167MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/pipeline/forests/plot_7_cut.npy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To run the TreeLearn pipeline interactively in google colab, we import the function run_treelearn_pipeline. This function takes as argument the config dict. We import the pipeline.yaml as the config dict and print it.\n",
        "\n",
        "We adjust some entries in the config dict to fit to the setting in google colab and speed up the pipeline. We also initialize the logger so that the progress in the pipeline is printed.\n"
      ],
      "metadata": {
        "id": "tZREpAa-s0Fp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPbQGPxNdwzL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "outputId": "6e2dd44b-616e-447d-a4d1-b626edf448cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ 'dataloader': {'batch_size': 1, 'num_workers': 1},\n",
            "  'dataset_test': { 'data_root': '../datasets_simlink/data_trees/validation_data/tiles',\n",
            "                    'inner_square_edge_length': 8,\n",
            "                    'training': False,\n",
            "                    'use_tree_height_in_offset': True},\n",
            "  'forest_path': '../datasets_simlink/data_trees/test/forests/L1W.npy',\n",
            "  'fp16': True,\n",
            "  'global_filtering': True,\n",
            "  'grouping': {'npoint_thr': 100, 'radius': 0.6, 'tree_conf_thresh': 0.5},\n",
            "  'local_filtering': False,\n",
            "  'model': { 'channels': 32,\n",
            "             'dim_coord': 3,\n",
            "             'dim_feat': 4,\n",
            "             'fixed_modules': [],\n",
            "             'kernel_size': 3,\n",
            "             'max_num_points_per_voxel': 3,\n",
            "             'mode': 'pointwise',\n",
            "             'n_voxels_in_each_direction': 20,\n",
            "             'num_blocks': 7,\n",
            "             'spatial_shape': [500, 500, 1000],\n",
            "             'use_coords': False,\n",
            "             'use_feats': False,\n",
            "             'voxel_size': 0.1},\n",
            "  'model_classifier': { 'dim_feat': 32,\n",
            "                        'max_num_points_per_voxel': 100,\n",
            "                        'mode': 'classifier',\n",
            "                        'num_blocks': 3,\n",
            "                        'spatial_shape': None,\n",
            "                        'use_feats': True},\n",
            "  'pretrain_classifier': 'work_dirs/train_classifier_80e_finetuned/finetuned_checkpoint_classifier.pth',\n",
            "  'pretrain_pointwise': 'work_dirs/finetune_pointwise_all_data/finetuned_checkpoint_pointwise_prediction.pth',\n",
            "  'sample_generation': { 'inner_edge': 8,\n",
            "                         'outer_edge': 11,\n",
            "                         'sample_generator': { 'multiplier_sor': 1,\n",
            "                                               'n_neigh_sor': 2,\n",
            "                                               'npoints_rad': 5,\n",
            "                                               'rad': 0.2086},\n",
            "                         'search_radius_features': None,\n",
            "                         'stride': 0.5,\n",
            "                         'voxel_size': 0.1},\n",
            "  'save_cfg': { 'only_pointwise': False,\n",
            "                'return_type': 'voxelized',\n",
            "                'save_format': 'npy',\n",
            "                'save_pointwise': True,\n",
            "                'save_treewise': True},\n",
            "  'shape_cfg': { 'alpha': 0,\n",
            "                 'buffer_size_to_determine_edge_trees': 0.3,\n",
            "                 'outer_remove': 11},\n",
            "  'tile_generation': True}\n",
            "2023-11-07 12:05:32,986 - INFO - Test log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:Test log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<StreamHandler stdout (INFO)>]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/TreeLearn/tools/pipeline\")\n",
        "from pipeline import run_treelearn_pipeline\n",
        "import argparse, pprint\n",
        "from tree_learn.util import get_config\n",
        "\n",
        "config_path = \"/content/TreeLearn/configs/pipeline/pipeline.yaml\"\n",
        "config = get_config(config_path)\n",
        "\n",
        "# adjust config\n",
        "config.forest_path = \"/content/pipeline/forests/\" + forest_name\n",
        "config.dataset_test.data_root = \"/content/pipeline/tiles\"\n",
        "config.tile_generation = True\n",
        "config.pretrain_classifier = \"/content/checkpoints/finetuned_checkpoint_classifier.pth\"\n",
        "config.pretrain_pointwise = \"/content/checkpoints/finetuned_checkpoint_pointwise_prediction.pth\"\n",
        "config.sample_generation.stride = 0.9 # small overlap\n",
        "config.shape_cfg.outer_remove = False # default value = 11\n",
        "config.save_cfg.save_treewise = False\n",
        "config.save_cfg.return_type = \"voxelized_and_denoised\"\n",
        "print(pprint.pformat(config.toDict(), indent=2))\n",
        "\n",
        "import logging\n",
        "logger = logging.getLogger(\"softgroup\")\n",
        "for handler in logger.handlers[:]:\n",
        "    logger.removeHandler(handler)\n",
        "logging.basicConfig()\n",
        "ch = logging.StreamHandler(sys.stdout)\n",
        "ch.setLevel(logging.INFO)\n",
        "# create formatter and add it to the handlers\n",
        "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "ch.setFormatter(formatter)\n",
        "logger.addHandler(ch)\n",
        "logger.setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After having set all the correct settings in the config file, it remains to run the pipeline. Please keep in mind that fully running it for the example point cloud takes around 15 minutes.\n",
        "\n"
      ],
      "metadata": {
        "id": "6neoLf6l2zcF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKh7yZ3ld1o3",
        "outputId": "3fba8b4b-8bf3-4dec-db38-07033fc455c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:05:49,724 - INFO - Munch({'sample_generation': Munch({'voxel_size': 0.1, 'search_radius_features': None, 'inner_edge': 8, 'outer_edge': 11, 'stride': 0.9, 'sample_generator': Munch({'n_neigh_sor': 2, 'multiplier_sor': 1, 'rad': 0.2086, 'npoints_rad': 5})}), 'model': Munch({'mode': 'pointwise', 'kernel_size': 3, 'channels': 32, 'num_blocks': 7, 'use_feats': False, 'use_coords': False, 'dim_coord': 3, 'dim_feat': 4, 'max_num_points_per_voxel': 3, 'fixed_modules': [], 'spatial_shape': [500, 500, 1000], 'n_voxels_in_each_direction': 20, 'voxel_size': 0.1}), 'grouping': Munch({'npoint_thr': 100, 'radius': 0.6, 'tree_conf_thresh': 0.5}), 'forest_path': '/content/pipeline/forests/plot_7_cut.npy', 'pretrain_pointwise': '/content/checkpoints/finetuned_checkpoint_pointwise_prediction.pth', 'pretrain_classifier': '/content/checkpoints/finetuned_checkpoint_classifier.pth', 'fp16': True, 'tile_generation': True, 'global_filtering': True, 'local_filtering': False, 'model_classifier': Munch({'mode': 'classifier', 'use_feats': True, 'dim_feat': 32, 'num_blocks': 3, 'max_num_points_per_voxel': 100, 'spatial_shape': None}), 'dataloader': Munch({'batch_size': 1, 'num_workers': 1}), 'shape_cfg': Munch({'alpha': 0, 'outer_remove': False, 'buffer_size_to_determine_edge_trees': 0.3}), 'save_cfg': Munch({'only_pointwise': False, 'save_pointwise': True, 'save_treewise': False, 'return_type': 'voxelized_and_denoised', 'save_format': 'npy'}), 'dataset_test': Munch({'training': False, 'data_root': '/content/pipeline/tiles', 'inner_square_edge_length': 8, 'use_tree_height_in_offset': True})})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:Munch({'sample_generation': Munch({'voxel_size': 0.1, 'search_radius_features': None, 'inner_edge': 8, 'outer_edge': 11, 'stride': 0.9, 'sample_generator': Munch({'n_neigh_sor': 2, 'multiplier_sor': 1, 'rad': 0.2086, 'npoints_rad': 5})}), 'model': Munch({'mode': 'pointwise', 'kernel_size': 3, 'channels': 32, 'num_blocks': 7, 'use_feats': False, 'use_coords': False, 'dim_coord': 3, 'dim_feat': 4, 'max_num_points_per_voxel': 3, 'fixed_modules': [], 'spatial_shape': [500, 500, 1000], 'n_voxels_in_each_direction': 20, 'voxel_size': 0.1}), 'grouping': Munch({'npoint_thr': 100, 'radius': 0.6, 'tree_conf_thresh': 0.5}), 'forest_path': '/content/pipeline/forests/plot_7_cut.npy', 'pretrain_pointwise': '/content/checkpoints/finetuned_checkpoint_pointwise_prediction.pth', 'pretrain_classifier': '/content/checkpoints/finetuned_checkpoint_classifier.pth', 'fp16': True, 'tile_generation': True, 'global_filtering': True, 'local_filtering': False, 'model_classifier': Munch({'mode': 'classifier', 'use_feats': True, 'dim_feat': 32, 'num_blocks': 3, 'max_num_points_per_voxel': 100, 'spatial_shape': None}), 'dataloader': Munch({'batch_size': 1, 'num_workers': 1}), 'shape_cfg': Munch({'alpha': 0, 'outer_remove': False, 'buffer_size_to_determine_edge_trees': 0.3}), 'save_cfg': Munch({'only_pointwise': False, 'save_pointwise': True, 'save_treewise': False, 'return_type': 'voxelized_and_denoised', 'save_format': 'npy'}), 'dataset_test': Munch({'training': False, 'data_root': '/content/pipeline/tiles', 'inner_square_edge_length': 8, 'use_tree_height_in_offset': True})})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:05:49,726 - INFO - #################### generating tiles ####################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:#################### generating tiles ####################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:05:49,729 - INFO - voxelizing data and features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:voxelizing data and features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:06:12,758 - INFO - getting tiles...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:getting tiles...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:06:12,799 - INFO - defining plot corners\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:defining plot corners\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:06:12,807 - INFO - setting up grid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:setting up grid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:06:13,366 - INFO - subset all points with outer square extensions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:subset all points with outer square extensions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:06:13,732 - INFO - only select chunks whose inner squares contain points\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:only select chunks whose inner squares contain points\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:06:14,401 - INFO - center chunks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:center chunks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:06:15,554 - INFO - denoise\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:denoise\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:14:33,448 - INFO - plot_7_cut: #################### getting pointwise predictions ####################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:plot_7_cut: #################### getting pointwise predictions ####################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:14:33,763 - INFO - Load val dataset: 36 scans\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:Load val dataset: 36 scans\n",
            "100%|██████████| 36/36 [00:44<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:15:18,718 - INFO - plot_7_cut: #################### ensembling predictions ####################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:plot_7_cut: #################### ensembling predictions ####################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:15:36,812 - INFO - plot_7_cut: #################### getting predicted instances ####################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:plot_7_cut: #################### getting predicted instances ####################\n",
            "9129it [00:00, 87778.17it/s]\n",
            "100%|██████████| 1318964/1318964 [00:06<00:00, 189286.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clustering\n",
            "2023-11-07 12:17:17,401 - INFO - plot_7_cut: #################### Run classifier on preliminary instances ####################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:plot_7_cut: #################### Run classifier on preliminary instances ####################\n",
            "100%|██████████| 51/51 [00:02<00:00, 18.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-07 12:17:32,384 - INFO - plot_7_cut: #################### Saving ####################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:softgroup:plot_7_cut: #################### Saving ####################\n"
          ]
        }
      ],
      "source": [
        "# run pipeline\n",
        "run_treelearn_pipeline(config)\n",
        "# tile generation runtime ~ 8-9 min"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If everything has run as expected, the segmented point cloud is now saved in the .ply format with labels in the directory /content/pipeline/results. It is also saved in the .npy format. You can easily download it by right-clicking and selecting download."
      ],
      "metadata": {
        "id": "zroEoOMU5DOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "coords = np.load(\"/content/pipeline/results/\" + forest_name.split(\".\")[0] + \"/full_forest/\" + forest_name)\n",
        "print(\"Number of identified trees:\", len(np.unique(coords[:,3])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H03fS-xgfIu_",
        "outputId": "daf28885-88e4-4ce4-d0a1-155641b9e7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of identified trees: 33\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}